{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "\n",
    "* Implement and train a fully connected and a convolutional neural net using PyTorch\n",
    "* We will also illustrate how the ConvNet makes use of specific assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% run plot_helper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "#helper function to count number of parameters in a neural neywrok\n",
    "def get_n_params(model):\n",
    "    np=0\n",
    "    for p in list(model.parameters()):\n",
    "        np += p.nelement()\n",
    "    return np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Dataset (MNIST)\n",
    "\n",
    "\n",
    "We can use PyTorch DataLoader utilities for this. This will download, shuffle, normalize data and arrange it in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input_size  = 28*28   # images are 28x28 pixels\n",
    "output_size = 10      # there are 10 classes\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show some images\n",
    "plt.figure()\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    image, _ = train_loader.dataset.__getitem__(i)\n",
    "    plt.imshow(image.squeeze().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the model classes\n",
    "\n",
    "``nn.Module`` - Neural network module. Convenient way of encapsulating parameters, with helpers for moving them to GPU, exporting, loading, etc.\n",
    "\n",
    "All our neural nets will inherit from this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC2Layer(nn.Module):\n",
    "    \"\"\"A simple Fully Connected neural net class.\n",
    "    \n",
    "    In PyTorch, subclassing your model from torch.nn.Module\n",
    "    takes care of low-level concerns for you such as defining\n",
    "    the backward pass and keeping track of network parameters.\n",
    "    \n",
    "    Arguments\n",
    "    ----------\n",
    "    input_size : int\n",
    "        The number of features in the input tensor.\n",
    "    n_hidden : int\n",
    "        The number of features in the hidden state of the FC layer.\n",
    "    output_size : int\n",
    "        The number of classes in the output tensor.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, n_hidden, output_size):\n",
    "        super(FC2Layer, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.linear1 = nn.Linear(input_size, n_hidden)\n",
    "        self.linear2 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.linear3 = nn.Linear(n_hidden, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #since the images are square, we need to flatten before \n",
    "        #feeding to the linear layer\n",
    "        x = x.view(-1, self.input_size)\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class CNN(nn.Module):\n",
    "    \"\"\"A simple CNN class.\n",
    "    \n",
    "    In PyTorch, subclassing your model from torch.nn.Module\n",
    "    takes care of low-level concerns for you such as defining\n",
    "    the backward pass and keeping track of network parameters.\n",
    "    \n",
    "    Arguments\n",
    "    ----------\n",
    "    input_size : int\n",
    "        The number of features in the input tensor.\n",
    "    n_feature : int\n",
    "        The number of output channels of the CNN, or the number of \n",
    "        feature maps produced at the output of the layer\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, n_feature):\n",
    "        super().__init__()\n",
    "        self.n_feature = n_feature\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=n_feature, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(n_feature, n_feature, kernel_size=5)\n",
    "        #the parameters below are manually tuned to get \n",
    "        #overall number of trainable parametres close to that in FC neural net\n",
    "        self.fc1 = nn.Linear(n_feature*4*4, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        x = x.view(-1, self.n_feature*4*4)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence model: alternative API\n",
    "\n",
    "```python\n",
    "network = nn.Sequential(\n",
    "    nn.Linear(input_size, n_hidden), \n",
    "    nn.ReLU(), \n",
    "    nn.Linear(n_hidden, n_hidden), \n",
    "    nn.ReLU(), \n",
    "    nn.Linear(n_hidden, output_size), \n",
    "    nn.LogSoftmax(dim=1)\n",
    ")\n",
    "```        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running on a GPU: device string\n",
    "\n",
    "Switching between CPU and GPU in PyTorch is controlled via a device string, which will seemlessly determine whether GPU is available, falling back to CPU if not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list = []\n",
    "\n",
    "def train(epoch, model, train_loader, optimizer, device, perm=torch.arange(0, 784).long()):\n",
    "    \"\"\"Train a model to classify handwritten digits using FC neural net\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : torch.nn.Module\n",
    "        The model to train.\n",
    "    train_loader : The data generator instance used to produce training data.\n",
    "    optimizer : torch.optim.Optimizer\n",
    "        The optimization algorithm used to updated the network parameters.\n",
    "    device : torch.device\n",
    "        The device to which tensors will be moved.\n",
    "    perm : torch.tensor\n",
    "        Tensor defining a random permutation of indices, \n",
    "        the default leaves indices in original order  \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        The number of correctly classified sequences and the loss, respectively.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set the model to training mode. This will turn on layers that would\n",
    "    # otherwise behave differently during evaluation, such as dropout or batch normalization.\n",
    "    model.train()\n",
    "    \n",
    "    # Iterate over every batch\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "  \n",
    "        # permute pixels\n",
    "        data = data.view(-1, 28*28)\n",
    "        data = data[:, perm]\n",
    "        data = data.view(-1, 1, 28, 28).to(device)\n",
    "            \n",
    "        # For each new batch, clear the gradient buffers of the optimized parameters.\n",
    "        # Otherwise, gradients from the previous batch would be accumulated.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Perform the forward pass of the model.\n",
    "        output = model(data)\n",
    "        \n",
    "        # Compute the value of the loss for this batch.\n",
    "        loss = F.nll_loss(output, target)\n",
    "        \n",
    "        #Backpropagation step\n",
    "        loss.backward()\n",
    "        #Weight update\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "def test(model, test_loader, optimizer, device, perm=torch.arange(0, 784).long()):\n",
    "    \"\"\"Train a model to classify handwritten digits using FC neural net\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : torch.nn.Module\n",
    "        The model to train.\n",
    "    test_loader : The data generator instance used to produce test data.\n",
    "    optimizer : torch.optim.Optimizer\n",
    "        The optimization algorithm used to updated the network parameters.\n",
    "    device : torch.device\n",
    "        The device to which tensors will be moved.\n",
    "    perm : torch.tensor\n",
    "        Tensor defining a random permutation of indices, \n",
    "        the default leaves indices in original order  \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        The number of correctly classified sequences and the loss, respectively.\n",
    "    \"\"\"\n",
    "        \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        # permute pixels\n",
    "        data = data.view(-1, 28*28)\n",
    "        data = data[:, perm]\n",
    "        data = data.view(-1, 1, 28, 28).to(device)\n",
    "        \n",
    "        #perform forward pass\n",
    "        output = model(data)\n",
    "        \n",
    "        # sum up batch loss \n",
    "        test_loss += F.nll_loss(output, target, size_average=False).item()   \n",
    "        \n",
    "        # get the index of the max log-probability   \n",
    "        pred = output.data.max(1, keepdim=True)[1]                                                               \n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    accuracy_list.append(accuracy)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a small fully-connected network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 8    # number of hidden units\n",
    "\n",
    "model = FC2Layer(input_size, n_hidden, output_size)\n",
    "model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "print('Number of parameters: {}'.format(get_n_params(model)))\n",
    "\n",
    "for epoch in range(0, 1):\n",
    "    train(epoch, model, train_loader, optimizer, device)\n",
    "    test(model, test_loader, optimizer, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a ConvNet with the same number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings \n",
    "n_features    = 6     # number of feature maps\n",
    "\n",
    "model = CNN(input_size, n_features)\n",
    "model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "print('Number of parameters: {}'.format(get_n_params(model)))\n",
    "\n",
    "for epoch in range(0, 1):\n",
    "    train(epoch, model, train_loader, optimizer, device)\n",
    "    test(model, test_loader, optimizer, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The ConvNet performs better with the same number of parameters, thanks to its use of prior knowledge about images\n",
    "\n",
    "* Use of convolution: Locality and stationarity in images\n",
    "* Pooling: builds in some translation invariance\n",
    "\n",
    "# What happens if the assumptions are no longer true?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "perm = torch.randperm(784)\n",
    "plt.figure()\n",
    "for i in range(10):\n",
    "    image, _ = train_loader.dataset.__getitem__(i)\n",
    "    # permute pixels\n",
    "    image_perm = image.view(-1, 28*28).clone()\n",
    "    image_perm = image_perm[:, perm]\n",
    "    image_perm = image_perm.view(-1, 1, 28, 28)\n",
    "    plt.subplot(4, 5, i + 1)\n",
    "    plt.imshow(image.squeeze().numpy())\n",
    "    plt.axis('off')\n",
    "    plt.subplot(4, 5, i + 11)\n",
    "    plt.imshow(image_perm.squeeze().numpy())\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvNet with permuted pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings \n",
    "n_features    = 6     # number of feature maps\n",
    "\n",
    "model = CNN(input_size, n_features)\n",
    "model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "print('Number of parameters: {}'.format(get_n_params(model)))\n",
    "\n",
    "for epoch in range(0, 1):\n",
    "    train(epoch, model, train_loader, optimizer, device, perm)\n",
    "    test(model, test_loader, optimizer, device, perm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully-Connected with Permuted Pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden    = 8    # number of hidden units\n",
    "\n",
    "model = FC2Layer(input_size, n_hidden, output_size)\n",
    "model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "print('Number of parameters: {}'.format(get_n_params(model)))\n",
    "\n",
    "for epoch in range(0, 1):\n",
    "    train(epoch, model, train_loader, optimizer, device, perm)\n",
    "    test(model, test_loader, optimizer, device, perm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The ConvNet's performance drops when we permute the pixels, but the Fully-Connected Network's performance stays the same\n",
    "\n",
    "* ConvNet makes the assumption that pixels lie on a grid and are stationary/local\n",
    "* It loses performance when this assumption is wrong\n",
    "* The fully-connected network does not make this assumption\n",
    "* It does less well when it is true, since it doesn't take advantage of this prior knowledge\n",
    "* But it doesn't suffer when the assumption is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(('NN image', 'CNN image',\n",
    "         'CNN scrambled', 'NN scrambled'),\n",
    "        accuracy_list, width=0.4)\n",
    "plt.ylim((min(accuracy_list)-5, 96))\n",
    "plt.ylabel('Accuracy [%]')\n",
    "for tick in plt.gca().xaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(20)\n",
    "plt.title('Performance comparison');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Codas ML",
   "language": "python",
   "name": "codasml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
